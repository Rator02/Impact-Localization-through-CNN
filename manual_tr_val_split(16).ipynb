{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d714a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import itertools\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf7ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8a753",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00035a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ratho\\\\Desktop\\\\CI\\\\Project_B_Data\\\\DATA'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae04ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\ratho\\\\Desktop\\\\CI\\\\Project_B_Data\\\\DATA\\\\imdata2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93e1852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ratho\\\\Desktop\\\\CI\\\\Project_B_Data\\\\DATA\\\\imdata2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f670e2",
   "metadata": {},
   "source": [
    "## Reading all the image paths present in a folder and classifying it into 16 different folders on the basis of x and y coordinates: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96032d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = glob.glob(\"imdata2/*.png\")\n",
    "im_paths = pd.Series(fp, name = 'image_paths').astype(str)\n",
    "im_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7348046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coordi = []\n",
    "y_coordi = []\n",
    "folder_path = 'imdata2'\n",
    "\n",
    "for i in range(len(im_paths)):\n",
    "    w = os.path.splitext(os.path.split(im_paths[i])[1])[0]\n",
    "    x_coordi.append(w.split('_')[0])\n",
    "    y_coordi.append(w.split('_')[1])\n",
    "    \n",
    "    ######################################################################## splitting Q2\n",
    "    if ('175'<=x_coordi[i] <= '213' and '250'< y_coordi[i] <= '288'):\n",
    "        folder_name = 'q23'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('213'< x_coordi[i] <= '250' and '288'< y_coordi[i] <= '325'):\n",
    "        folder_name = 'q21'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('175'<=x_coordi[i] <= '213' and '288'< y_coordi[i] <= '325'):\n",
    "        folder_name = 'q22'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('213'< x_coordi[i] <= '250' and '250'< y_coordi[i] <= '288'):\n",
    "        folder_name = 'q24'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "    ################################################################################## splitting Q3\n",
    "    \n",
    "    if ('175'<=x_coordi[i] <= '213' and '175'<=y_coordi[i] <= '213'):\n",
    "        folder_name = 'q33'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('213'< x_coordi[i] <= '250' and '213'< y_coordi[i] <= '250'):\n",
    "        folder_name = 'q31'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('175'<=x_coordi[i] <= '213' and '213'< y_coordi[i] <= '250'):\n",
    "        folder_name = 'q32'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('213'< x_coordi[i] <= '250' and '175'<=y_coordi[i] <= '213'):\n",
    "        folder_name = 'q34'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "    #################################################################################  splitting Q1\n",
    "    \n",
    "    if ('250'< x_coordi[i] <= '288' and '250'< y_coordi[i] <= '288'):\n",
    "        folder_name = 'q13'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('288'< x_coordi[i] <= '325' and '288'< y_coordi[i] <= '325'):\n",
    "        folder_name = 'q11'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('250'< x_coordi[i] <= '288' and '288'< y_coordi[i] <= '325'):\n",
    "        folder_name = 'q12'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('288'< x_coordi[i] <= '325' and '250'< y_coordi[i] <= '288'):\n",
    "        folder_name = 'q14'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "    ###############################################################################  spliting Q4\n",
    "    \n",
    "    if ('250'< x_coordi[i] <= '288' and '175'<=y_coordi[i] <= '213'):\n",
    "        folder_name = 'q43'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('288'< x_coordi[i] <= '325' and '213'< y_coordi[i] <= '250'):\n",
    "        folder_name = 'q41'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('250'< x_coordi[i] <= '288' and '213'< y_coordi[i] <= '250'):\n",
    "        folder_name = 'q42'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)\n",
    "\n",
    "    if ('288'< x_coordi[i] <= '325' and '175'<=y_coordi[i] <= '213'):\n",
    "        folder_name = 'q44'\n",
    "        new_path = os.path.join(folder_path, folder_name)\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "\n",
    "        old_image_path = os.path.join(im_paths[i])\n",
    "        new_image_path = os.path.join(new_path, os.path.split(im_paths[i])[1])\n",
    "        shutil.move(old_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e1d8e1",
   "metadata": {},
   "source": [
    "## manually splitting the training and validation data, since there were some shape errors while running CNN by using automatic train, test split functions on dataframe (which i dont have any clues about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bb30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('imdata2/val_q11') is False:\n",
    "    ##########################################################  creating validation folders\n",
    "    os.makedirs('val_q11')\n",
    "    os.makedirs('val_q12')\n",
    "    os.makedirs('val_q13')\n",
    "    os.makedirs('val_q14')\n",
    "    \n",
    "    os.makedirs('val_q21')\n",
    "    os.makedirs('val_q22')\n",
    "    os.makedirs('val_q23')\n",
    "    os.makedirs('val_q24')\n",
    "    \n",
    "    os.makedirs('val_q31')\n",
    "    os.makedirs('val_q32')\n",
    "    os.makedirs('val_q33')\n",
    "    os.makedirs('val_q34')\n",
    "    \n",
    "    os.makedirs('val_q41')\n",
    "    os.makedirs('val_q42')\n",
    "    os.makedirs('val_q43')\n",
    "    os.makedirs('val_q44')\n",
    "    ############################################################  creating training folders\n",
    "    \n",
    "    os.makedirs('tr_q11')\n",
    "    os.makedirs('tr_q12')\n",
    "    os.makedirs('tr_q13')\n",
    "    os.makedirs('tr_q14')\n",
    "    \n",
    "    os.makedirs('tr_q21')\n",
    "    os.makedirs('tr_q22')\n",
    "    os.makedirs('tr_q23')\n",
    "    os.makedirs('tr_q24')\n",
    "    \n",
    "    os.makedirs('tr_q31')\n",
    "    os.makedirs('tr_q32')\n",
    "    os.makedirs('tr_q33')\n",
    "    os.makedirs('tr_q34')\n",
    "    \n",
    "    os.makedirs('tr_q41')\n",
    "    os.makedirs('tr_q42')\n",
    "    os.makedirs('tr_q43')\n",
    "    os.makedirs('tr_q44')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3769e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################  moving some files randomly from q11 to tr_q11 and some to val_q11\n",
    "#######################################################  and doing this for each of the 16 folders\n",
    "for c in random.sample(glob.glob('q11\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q11')\n",
    "for c in random.sample(glob.glob('q12\\*.png'), 46):\n",
    "    shutil.move(c,'tr_q12')\n",
    "for c in random.sample(glob.glob('q13\\*.png'), 33):\n",
    "    shutil.move(c,'tr_q13')\n",
    "for c in random.sample(glob.glob('q14\\*.png'), 46):\n",
    "    shutil.move(c,'tr_q14')\n",
    "\n",
    "for c in random.sample(glob.glob('q11\\*.png'), 10):\n",
    "    shutil.move(c,'val_q11')\n",
    "for c in random.sample(glob.glob('q12\\*.png'), 10):\n",
    "    shutil.move(c,'val_q12')\n",
    "for c in random.sample(glob.glob('q13\\*.png'), 10):\n",
    "    shutil.move(c,'val_q13')\n",
    "for c in random.sample(glob.glob('q14\\*.png'), 10):\n",
    "    shutil.move(c,'val_q14')\n",
    "    \n",
    "#############################################################################\n",
    "\n",
    "for c in random.sample(glob.glob('q21\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q21')\n",
    "for c in random.sample(glob.glob('q22\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q22')\n",
    "for c in random.sample(glob.glob('q23\\*.png'), 46):\n",
    "    shutil.move(c,'tr_q23')\n",
    "for c in random.sample(glob.glob('q24\\*.png'), 37):\n",
    "    shutil.move(c,'tr_q24')\n",
    "\n",
    "for c in random.sample(glob.glob('q21\\*.png'), 10):\n",
    "    shutil.move(c,'val_q21')\n",
    "for c in random.sample(glob.glob('q22\\*.png'), 10):\n",
    "    shutil.move(c,'val_q22')\n",
    "for c in random.sample(glob.glob('q23\\*.png'), 10):\n",
    "    shutil.move(c,'val_q23')\n",
    "for c in random.sample(glob.glob('q24\\*.png'), 10):\n",
    "    shutil.move(c,'val_q24')\n",
    "    \n",
    "###############################################################################\n",
    "\n",
    "for c in random.sample(glob.glob('q31\\*.png'), 42):\n",
    "    shutil.move(c,'tr_q31')\n",
    "for c in random.sample(glob.glob('q32\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q32')\n",
    "for c in random.sample(glob.glob('q33\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q33')\n",
    "for c in random.sample(glob.glob('q34\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q34')\n",
    "\n",
    "for c in random.sample(glob.glob('q31\\*.png'), 10):\n",
    "    shutil.move(c,'val_q31')\n",
    "for c in random.sample(glob.glob('q32\\*.png'), 10):\n",
    "    shutil.move(c,'val_q32')\n",
    "for c in random.sample(glob.glob('q33\\*.png'), 10):\n",
    "    shutil.move(c,'val_q33')\n",
    "for c in random.sample(glob.glob('q34\\*.png'), 10):\n",
    "    shutil.move(c,'val_q34')\n",
    "    \n",
    "#################################################################################\n",
    "\n",
    "for c in random.sample(glob.glob('q41\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q41')\n",
    "for c in random.sample(glob.glob('q42\\*.png'), 37):\n",
    "    shutil.move(c,'tr_q42')\n",
    "for c in random.sample(glob.glob('q43\\*.png'), 46):\n",
    "    shutil.move(c,'tr_q43')\n",
    "for c in random.sample(glob.glob('q44\\*.png'), 54):\n",
    "    shutil.move(c,'tr_q44')\n",
    "\n",
    "for c in random.sample(glob.glob('q41\\*.png'), 10):\n",
    "    shutil.move(c,'val_q41')\n",
    "for c in random.sample(glob.glob('q42\\*.png'), 10):\n",
    "    shutil.move(c,'val_q42')\n",
    "for c in random.sample(glob.glob('q43\\*.png'), 10):\n",
    "    shutil.move(c,'val_q43')\n",
    "for c in random.sample(glob.glob('q44\\*.png'), 10):\n",
    "    shutil.move(c,'val_q44')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbbcb87",
   "metadata": {},
   "source": [
    "## Generating batches from train and val folders (after collecting all the tr_q## and val_q## into train and val folders respectively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d41a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'train'\n",
    "val_path = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e13701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 765 images belonging to 16 classes.\n",
      "Found 160 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['q11','q12','q13','q14',\n",
    "                                                                               'q21','q22','q23','q24',\n",
    "                                                                               'q31','q32','q33','q34',\n",
    "                                                                               'q41','q42','q43','q44'], batch_size = 5)\n",
    "val_batches = ImageDataGenerator(preprocessing_function = tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=val_path, target_size=(224,224), classes=['q11','q12','q13','q14',\n",
    "                                                                               'q21','q22','q23','q24',\n",
    "                                                                               'q31','q32','q33','q34',\n",
    "                                                                               'q41','q42','q43','q44'], batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "203e7f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_batches.n == 765\n",
    "assert val_batches.n == 160\n",
    "\n",
    "assert train_batches.num_classes == val_batches.num_classes == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef0b1e",
   "metadata": {},
   "source": [
    "## Just an example of how a single batch of 5 images has been preprocessed by keras vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92058316",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a069bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(10,10))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac976f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41b972",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09c3ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=(3,3), activation = 'relu', padding='same', input_shape=(224,224,3)),\n",
    "        MaxPool2D(pool_size=(2,2), strides=2),\n",
    "        Conv2D(filters=64, kernel_size=(3,3), activation = 'relu', padding='same'),\n",
    "        MaxPool2D(pool_size=(2,2), strides=2),\n",
    "        Flatten(),\n",
    "        Dense(units=16, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e614ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 224, 224, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200704)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                3211280   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,230,672\n",
      "Trainable params: 3,230,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2869d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b353873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "153/153 - 36s - loss: 29.2629 - accuracy: 0.3882 - val_loss: 2.5487 - val_accuracy: 0.6250 - 36s/epoch - 236ms/step\n",
      "Epoch 2/20\n",
      "153/153 - 30s - loss: 1.4127 - accuracy: 0.7072 - val_loss: 1.4984 - val_accuracy: 0.6812 - 30s/epoch - 198ms/step\n",
      "Epoch 3/20\n",
      "153/153 - 31s - loss: 0.9066 - accuracy: 0.8078 - val_loss: 0.9398 - val_accuracy: 0.7812 - 31s/epoch - 200ms/step\n",
      "Epoch 4/20\n",
      "153/153 - 31s - loss: 0.4284 - accuracy: 0.8837 - val_loss: 0.5991 - val_accuracy: 0.8125 - 31s/epoch - 201ms/step\n",
      "Epoch 5/20\n",
      "153/153 - 30s - loss: 0.2950 - accuracy: 0.9137 - val_loss: 0.8291 - val_accuracy: 0.8000 - 30s/epoch - 198ms/step\n",
      "Epoch 6/20\n",
      "153/153 - 30s - loss: 0.2905 - accuracy: 0.9203 - val_loss: 0.9583 - val_accuracy: 0.8188 - 30s/epoch - 197ms/step\n",
      "Epoch 7/20\n",
      "153/153 - 30s - loss: 0.3527 - accuracy: 0.9098 - val_loss: 0.8737 - val_accuracy: 0.8188 - 30s/epoch - 198ms/step\n",
      "Epoch 8/20\n",
      "153/153 - 31s - loss: 0.1617 - accuracy: 0.9621 - val_loss: 0.8139 - val_accuracy: 0.8062 - 31s/epoch - 200ms/step\n",
      "Epoch 9/20\n",
      "153/153 - 30s - loss: 0.0812 - accuracy: 0.9739 - val_loss: 0.9115 - val_accuracy: 0.8188 - 30s/epoch - 198ms/step\n",
      "Epoch 10/20\n",
      "153/153 - 31s - loss: 0.0560 - accuracy: 0.9804 - val_loss: 0.7203 - val_accuracy: 0.8125 - 31s/epoch - 204ms/step\n",
      "Epoch 11/20\n",
      "153/153 - 31s - loss: 0.0394 - accuracy: 0.9922 - val_loss: 0.8689 - val_accuracy: 0.8250 - 31s/epoch - 206ms/step\n",
      "Epoch 12/20\n",
      "153/153 - 31s - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.7119 - val_accuracy: 0.8375 - 31s/epoch - 205ms/step\n",
      "Epoch 13/20\n",
      "153/153 - 31s - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.7051 - val_accuracy: 0.8500 - 31s/epoch - 203ms/step\n",
      "Epoch 14/20\n",
      "153/153 - 31s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.6963 - val_accuracy: 0.8562 - 31s/epoch - 205ms/step\n",
      "Epoch 15/20\n",
      "153/153 - 31s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.7058 - val_accuracy: 0.8500 - 31s/epoch - 204ms/step\n",
      "Epoch 16/20\n",
      "153/153 - 32s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.8500 - 32s/epoch - 206ms/step\n",
      "Epoch 17/20\n",
      "153/153 - 31s - loss: 9.7344e-04 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.8562 - 31s/epoch - 204ms/step\n",
      "Epoch 18/20\n",
      "153/153 - 31s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7221 - val_accuracy: 0.8562 - 31s/epoch - 205ms/step\n",
      "Epoch 19/20\n",
      "153/153 - 31s - loss: 7.4025e-04 - accuracy: 1.0000 - val_loss: 0.7359 - val_accuracy: 0.8500 - 31s/epoch - 205ms/step\n",
      "Epoch 20/20\n",
      "153/153 - 31s - loss: 6.6451e-04 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.8500 - 31s/epoch - 203ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c77c412a00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches, validation_data=val_batches, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1dacf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
