{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9703fd38",
   "metadata": {},
   "source": [
    "Repository Link to Processed Data Files: https://gitfront.io/r/user-3027905/4e8c7576428c4d688ee6f1f785958d83ad775178/ProjectB-Group1/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e86bc",
   "metadata": {},
   "source": [
    "## Reading EPOT Data and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "924035d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2b03f5",
   "metadata": {},
   "source": [
    "---\n",
    "### Function Definitions\n",
    "**Function takes File Path and Returns a Numpy Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise AssertionError(file_path, 'Not Found!')\n",
    "\n",
    "    matdata = scipy.io.loadmat(file_path)\n",
    "    r, c = matdata['num_data'].shape\n",
    "    P = np.zeros((c,r))\n",
    "    for i in range(0,5):\n",
    "        P[i] = matdata['num_data'][:,i]\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db69aa0b",
   "metadata": {},
   "source": [
    "**Data Augmentation: Rotates the Position Vector and Allocates the Necessary Sensor Data to the New Quadrants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a08acb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_data(x, y, P_data, n):\n",
    "    #in order to reflect the vector easier, have to shift the origin from (0,0) to (250,250)\n",
    "    pos_orig = [[int(x)-250], [int(y)-250]]\n",
    "\n",
    "    pos_vector = np.zeros((2,1))\n",
    "    testQ2 = np.zeros(P_data.shape)\n",
    "\n",
    "    #this is defining the indexes for the new array that will be written.\n",
    "    #the check array has all the indexes that need to be there - T, P1, P2, P3, P4\n",
    "    check_ar = [0, 1, 2, 3, 4]\n",
    "    vor_n = n-1\n",
    "    nach_n = n+1\n",
    "    if nach_n > 4:\n",
    "        nach_n = 1\n",
    "\n",
    "    #this code basically identifies what number is missing from the \"check array\" after having used the idx array\n",
    "    #i didn't want to hand code everything and thought this was a more trustworthy way of identifying the last index for the\n",
    "    #augmented data array\n",
    "    idx = [0, vor_n, n, nach_n]\n",
    "    miss_idx = [i for i in check_ar if i not in idx]\n",
    "\n",
    "    #n implies the current quadrant of operation, the rotation matrix is defined accordingly\n",
    "    if n == 2:\n",
    "        rot_mat = [[-1, 0], [0, 1]]\n",
    "        testQ2[0, :] = P_data[0, :]\n",
    "        #P1 and P3 in the augmented array and original array are the same, PN ie P2 -> P4 and P4 -> P2\n",
    "        #miss_idx[0] is 4 here\n",
    "        testQ2[vor_n, :] = P_data[vor_n, :]\n",
    "        testQ2[n, :] = P_data[4, :]\n",
    "        testQ2[nach_n, :] = P_data[nach_n, :]\n",
    "        testQ2[miss_idx[0], :] = P_data[n, :]\n",
    "\n",
    "    if n == 3:\n",
    "        rot_mat = [[1, 0], [0, -1]]\n",
    "        testQ2[0, :] = P_data[0, :]\n",
    "        #P2 and P4 in the augmented array and original array are the same, PN ie  P3 -> P1 and P1 -> P3\n",
    "        #miss_idx[0] is 1 here\n",
    "        testQ2[vor_n, :] = P_data[vor_n, :]\n",
    "        testQ2[n, :] = P_data[1, :]\n",
    "        testQ2[nach_n, :] = P_data[nach_n, :]\n",
    "        testQ2[miss_idx[0], :] = P_data[n, :]\n",
    "\n",
    "    if n == 4:\n",
    "        rot_mat = [[-1, 0], [0, 1]]\n",
    "        testQ2[0, :] = P_data[0, :]\n",
    "        #P1 and P3 in the augmented array and original array are the same, PN ie P4 -> P2 and P2 -> P4\n",
    "        #miss_idx[0] is 2 here\n",
    "        testQ2[vor_n, :] = P_data[vor_n, :]\n",
    "        testQ2[n, :] = P_data[2, :]\n",
    "        testQ2[nach_n, :] = P_data[nach_n, :]\n",
    "        testQ2[miss_idx[0], :] = P_data[n, :]\n",
    "\n",
    "    #creating the new position vector and re-translating the position vector from (250,250) origin to (0,0) origin\n",
    "    pos_vector = np.matmul(rot_mat, pos_orig)\n",
    "    pos_vector = pos_vector + [[250], [250]]\n",
    "\n",
    "    #return the x and y coordinates of the position vector (it is a column vector: shape 2x1), and the augmented array\n",
    "    return pos_vector[0][0], pos_vector[1][0], testQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fc20ad",
   "metadata": {},
   "source": [
    "**Function to Write Array into a CSV File, or a Global .npy File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47f0589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####UNCOMMENT TO PREPARE DATA IN SEPARATE FILES\n",
    "def write_csv(write_ar, x, y):\n",
    "    #create the file name according to the x and y coordinates of the data\n",
    "    \n",
    "    #SPECIFY FOLDER TO SAVE FILES HERE\n",
    "    folder_name = r\"<INSERT PATH>\"\n",
    "    individual_name = str(int(x))+\"_\"+str(int(y))+\".csv\"\n",
    "    name = os.path.join(folder_name, individual_name)\n",
    "    \n",
    "    print(\"\\nWRITING: (\" + str(x)+\",\"+str(y) +\")\\n\")\n",
    "    \n",
    "    with open(name,'a') as csvfile:\n",
    "        np.savetxt(csvfile, write_ar, delimiter = \",\", header='X, Y, P1, P2, P3, P4')\n",
    "\n",
    "#_____________________________________________________________________________________________________\n",
    "#####UNCOMMENT TO PREPARE DATA IN SINGLE FILE\n",
    "\n",
    "#def write_csv(write_ar, x, y):\n",
    "#folder_name = r\"C:\\Users\\dell\\OneDrive\\Desktop\\CIE_B\\CutDataSets\\Augmented_Data\"\n",
    "#    name = os.path.join(folder_name, 'Augmented_Data.csv')\n",
    "#    with open(name,'a') as csvfile:\n",
    "#        if csvfile.tell() == 0:\n",
    "#            np.savetxt(csvfile, write_ar, delimiter = \",\", header='X, Y, P1, P2, P3, P4')\n",
    "#        else:\n",
    "#            np.savetxt(csvfile, write_ar, delimiter = \",\")\n",
    "#    \n",
    "#    name = os.path.join(folder_name, 'NP_TestData.npy')\n",
    "#    with open(name, 'ab') as f:\n",
    "#        np.save(f, write_ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66fca6",
   "metadata": {},
   "source": [
    "**Function to Get Final Array (X, Y, T, P1, P2, P3, P4)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e8b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes the (x,y) and the data array and combines everything into one and returns the final data array\n",
    "def getFinalArray(x, y, P):\n",
    "    pos = np.array([int(x), int(y)])\n",
    "    [r, c] = P.shape\n",
    "    print(\"Reading Coordinates: (\" + str(x) + \",\" + str(y) + \")\")\n",
    "\n",
    "    #confirm if array shape is (20000,5) and in case not, everything is flipped\n",
    "    if r<c:\n",
    "        P = np.transpose(P)\n",
    "        t = r\n",
    "        r = c\n",
    "        c = t\n",
    "\n",
    "    write_ar = np.zeros((r, c+2))\n",
    "\n",
    "    write_ar[:, 0] = x\n",
    "    write_ar[:, 1] = y\n",
    "\n",
    "    for i in range (0,5):\n",
    "        write_ar[:, i+2] = P[:, i]\n",
    "\n",
    "    return write_ar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5c1fc",
   "metadata": {},
   "source": [
    "**Function to Plot Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d90fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ar(ar):\n",
    "    ar = np.transpose(ar)\n",
    "    plt.plot(ar[2,:],'r',label=\"P1\") #CONTAINS YOUR 3RD ROW\n",
    "    plt.plot(ar[3,:],'g',label=\"P2\") #CONTAINS YOUR 4TH ROW\n",
    "    plt.plot(ar[4,:],'b',label=\"P3\") #CONTAINS YOUR 5TH ROW\n",
    "    plt.plot(ar[5,:],'y',label=\"P4\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.ylabel(\"V\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509136eb",
   "metadata": {},
   "source": [
    "---\n",
    "### Main File: Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b093bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the data frame that stores the EPOT_Data details\n",
    "file_location = pd.DataFrame(columns = ['X', 'Y', 'Path'], dtype = str)\n",
    "\n",
    "########################################################\n",
    "#INSERT PATH TO EPOT DATA\n",
    "mfolder = r\"<INSERT PATH>\"\n",
    "folder = (os.path.join(mfolder, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#READS THE FILES STORED AT THE PATH IN FOLDER\n",
    "#SAVES FILE PATH AND COORDINATES IN A DATAFRAME\n",
    "#You wrote this code, I've changed nothing except for the name splitting bit\n",
    "i = 0\n",
    "for name in glob.glob(folder):\n",
    "    fpath = name\n",
    "\n",
    "    #first split on the basis of the \\ in the path and take the last bit of it ie  EPOT_250_250.mat\n",
    "    split_name = re.split(r\"\\\\\", name)\n",
    "\n",
    "    #now split the last bit at the \"_\" and the \".\" so you get \"EPOT\", \"250\", \"250\", \"mat\" and then you just take the coordinates\n",
    "    coords = re.split(\"_|\\.\", split_name[-1])\n",
    "    #print(coords)\n",
    "\n",
    "    x_coord = coords[1]\n",
    "    y_coord = coords[2]\n",
    "    #print(x_coord + ',' + y_coord)\n",
    "\n",
    "    file_location.loc[i, 'X'] = str(x_coord)\n",
    "    file_location.loc[i, 'Y'] = str(y_coord)\n",
    "    file_location.loc[i, 'Path'] = fpath\n",
    "    i += 1\n",
    "\n",
    "#____________________________________________________________________\n",
    "file_location.to_csv(\"DataList.csv\", sep = \",\") #THIS FILE IS LATER USED TO CUT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835f9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "for idx, row in file_location.iterrows():\n",
    "    check = 0\n",
    "    x = row.X\n",
    "    y = row.Y\n",
    "    path = row.Path\n",
    "\n",
    "    P = read_data(path)\n",
    "    \n",
    "    if idx<250:\n",
    "        print(idx)\n",
    "        quad1 = getFinalArray(x, y, P)\n",
    "        \n",
    "        x2, y2, Q2 = aug_data(x, y, P, 2)\n",
    "        quad2 = getFinalArray(x2, y2, Q2)\n",
    "\n",
    "\n",
    "        x3, y3, Q3 = aug_data(x2, y2, Q2, 3)\n",
    "        quad3 = getFinalArray(x3, y3, Q3)\n",
    "\n",
    "        x4, y4, Q4 = aug_data(x3, y3, Q3, 4)\n",
    "        quad4 = getFinalArray(x4, y4, Q4)\n",
    "\n",
    "\n",
    "    #check if your point is actually on the origin\n",
    "        if int(x)==int(x3) and int(y)==int(y3):\n",
    "            write_csv(quad1, x, y)\n",
    "            continue\n",
    "\n",
    "    #check if your point lies on the y-axis\n",
    "        if int(x)==int(x2) and int(y)==int(y2):\n",
    "            write_csv(quad1, x, y)\n",
    "            check = 1\n",
    "        if int(x3)==int(x4) and int(y3)==int(y4):\n",
    "            write_csv(quad3, x3, y3)\n",
    "            check = 1\n",
    "\n",
    "    #check if your point lies on the x-axis\n",
    "        if int(x)==int(x4) and int(y)==int(y4):\n",
    "            write_csv(quad1, x, y)\n",
    "            check = 1\n",
    "        if int(x2)==int(x3) and int(y2)==int(y3):\n",
    "            write_csv(quad2, x2, y2)\n",
    "            check = 1\n",
    "\n",
    "    #if it doesn't lie on the axes, save all four quadrant data\n",
    "        if check == 0:\n",
    "            write_csv(quad1, x, y)\n",
    "            write_csv(quad2, x2, y2)\n",
    "            write_csv(quad3, x3, y3)\n",
    "            write_csv(quad4, x4, y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b322e9",
   "metadata": {},
   "source": [
    "---\n",
    "## Cutting the Augmented Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51d1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5700afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to cut the numerical data to where the values become non zero\n",
    "\n",
    "def num_data_prepro(file_locations):\n",
    "    \n",
    "    for idx in range(len(file_locations)):\n",
    "        \n",
    "        data_file = pd.read_csv(os.path.abspath(file_locations.iloc[idx,3]))\n",
    "        \n",
    "        cut_at_index = 0\n",
    "        \n",
    "        def nonzero_index(data_file):\n",
    "            for i in range(len(data_file.index)):\n",
    "                for j in range(3,6):\n",
    "                    if data_file.iloc[i,j] != 0:\n",
    "                        return i\n",
    "        \n",
    "        cut_at_index = nonzero_index(data_file)\n",
    "        \n",
    "#10000 data points are equal to half the total data, which seems to have enough usable information.\n",
    "#10000 datapoints = 0.1 ms = 0.0001 s\n",
    "                \n",
    "        data_file_cut = data_file.iloc[cut_at_index : cut_at_index+10000, : ]    \n",
    "        data_file_cut[' T'] = data_file[' T'].shift(cut_at_index)\n",
    "        \n",
    "    \n",
    "        \n",
    "        name = str(file_locations.iloc[idx,1]) + \"_\" +  str(file_locations.iloc[idx,2])\n",
    "\n",
    "#IMPORTANT: Specify where you want the new files to be saved       \n",
    "##___________INSERT PATH HERE___________________________________________________________________________________\n",
    "        path = r'<INSERT PATH>' + r'/' + name + r'.csv'\n",
    "        \n",
    "        data_file_cut.to_csv(path, sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50bf490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT PATH TO THE FILE CREATED TO THE DATALIST IN THE AUGMENTATION CODE \n",
    "\n",
    "file_locations = pd.read_csv('<INSERT PATH>/DataList.csv')\n",
    "num_data_prepro(file_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b8b432",
   "metadata": {},
   "source": [
    "---\n",
    "## Resampling and Normalisation of Cut Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ec56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################\n",
    "#this function takes the (x,y) and the data array and combines everything into one and returns the final data array\n",
    "def getResampledArray(x, y, P):\n",
    "    pos = np.array([int(x), int(y)])\n",
    "    [r, c] = P.shape\n",
    "    print(\"Reading Cordinates: (\" + str(x) + \",\" + str(y) + \")\")\n",
    "\n",
    "    #confirm if array shape is (20000,5) and in case not, everything is flipped\n",
    "    if r<c:\n",
    "        P = np.transpose(P)\n",
    "        t = r\n",
    "        r = c\n",
    "        c = t\n",
    "\n",
    "    #Here c = 7 (x, y, T, P1, P2, P3, P4)\n",
    "    temp_ar = np.zeros((c-3, r))\n",
    "    \n",
    "    for i in range (3, c):\n",
    "        temp_ar[i-3:] = P [:, i]\n",
    "\n",
    "    write_ar = np.zeros((c-1, 100))\n",
    "    write_ar[0, :] = x\n",
    "    write_ar[1, :] = y\n",
    "    \n",
    "    for i in range (2, 6):\n",
    "        write_ar[i, :] = signal.resample(temp_ar[i-2,:], 100)\n",
    "        write_ar[i, :] = 0.1+0.8*(write_ar[i,:]-np.min(write_ar[i, :]))/(np.max(write_ar[i, :])-np.min(write_ar[i, :]))\n",
    "    \n",
    "    write_ar = np.transpose(write_ar)\n",
    "    \n",
    "    return write_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d65bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFinalCSV(x, y, write_ar):\n",
    "    #create the file name according to the x and y coordinates of the data\n",
    "    \n",
    "#------------------------------------------------------------------------------------\n",
    "    #SPECIFY FOLDER PATH TO SAVE FILES HERE\n",
    "    folder_name = r\"<INSERT PATH>\"\n",
    "    individual_name = str(int(x))+\"_\"+str(int(y))+\".csv\"\n",
    "    name = os.path.join(folder_name, individual_name)\n",
    "    \n",
    "    \n",
    "    print(\"\\nWRITING: (\" + str(x)+\",\"+str(y) +\")\\n\")\n",
    "    \n",
    "    with open(name,'a') as csvfile:\n",
    "        np.savetxt(csvfile, write_ar, delimiter = \",\", header='X, Y, P1, P2, P3, P4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca74ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#define the data frame that stores the EPOT_Data details\n",
    "file_location = pd.DataFrame(columns = ['X', 'Y', 'Path'], dtype = str)\n",
    "\n",
    "########################################################\n",
    "#INSERT PATH TO FILES WHERE CUT DATA IS SAVED\n",
    "\n",
    "mfolder = r\"<INSERT PATH>\"\n",
    "folder = (os.path.join(mfolder, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9e3722",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "#READS THE FILES STORED AT THE PATH IN FOLDER\n",
    "#SAVES FILE PATH AND COORDINATES IN A DATAFRAME\n",
    "#You wrote this code, I've changed nothing except for the name splitting bit\n",
    "i = 0\n",
    "for name in glob.glob(folder):\n",
    "    fpath = name\n",
    "\n",
    "    #first split on the basis of the \\ in the path and take the last bit of it ie  EPOT_250_250.mat\n",
    "    split_name = re.split(r\"\\\\\", name)\n",
    "    #print(split_name)\n",
    "    \n",
    "    #now split the last bit at the \"_\" and the \".\"\n",
    "    coords = re.split(\"_|\\.\", split_name[-1])\n",
    "    #print(coords)\n",
    "\n",
    "    x_coord = coords[0]\n",
    "    y_coord = coords[1]\n",
    "    #print(x_coord + ',' + y_coord)\n",
    "\n",
    "    file_location.loc[i, 'X'] = str(x_coord)\n",
    "    file_location.loc[i, 'Y'] = str(y_coord)\n",
    "    file_location.loc[i, 'Path'] = fpath\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "for idx, row in file_location.iterrows():\n",
    "    check = 0\n",
    "    x = float(row.X)\n",
    "\n",
    "    y = float(row.Y)\n",
    "\n",
    "    path = row.Path\n",
    "    if idx < 950:\n",
    "        P = readCSV(path)\n",
    "        finalP = getResampledArray(x, y, P)\n",
    "        writeFinalCSV(x, y, finalP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcd574",
   "metadata": {},
   "source": [
    "---\n",
    "# Generating Flipped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9289df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise AssertionError(file_path, 'not found')\n",
    "    \n",
    "    P = np.genfromtxt(file_path, delimiter = ',', skip_header = 1)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59878ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipArray(x, y, P):\n",
    "    write_ar = np.zeros((np.shape(P)))\n",
    "    write_ar[:, 0] = P[:, 0]\n",
    "    write_ar[:, 1] = P[:, 1]\n",
    "    \n",
    "    \n",
    "    for i in range(2, 6):\n",
    "        temp_ar = np.negative(P[:, i])\n",
    "        write_ar[:, i] = np.transpose(temp_ar)\n",
    "    \n",
    "    return write_ar                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c464441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_csv(x, y, write_ar):\n",
    "    #create the file name according to the x and y coordinates of the data\n",
    "    #Specify folder to save\n",
    "    \n",
    "    folder_name = r\"<INSERT PATH HERE>\"\n",
    "    individual_name = str(int(x))+\"_\"+str(int(y))+\".csv\"\n",
    "    name = os.path.join(folder_name, individual_name)\n",
    "    \n",
    "    print(\"\\nWRITING: (\" + str(x)+\",\"+str(y) +\")\\n\")\n",
    "    \n",
    "    with open(name,'a') as csvfile:\n",
    "        np.savetxt(csvfile, write_ar, delimiter = \",\", header='X, Y, P1, P2, P3, P4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a479b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for name in glob.glob(folder):\n",
    "    fpath = name\n",
    "\n",
    "    #first split on the basis of the \\ in the path and take the last bit of it ie  EPOT_250_250.mat\n",
    "    split_name = re.split(r\"\\\\\", name)\n",
    "    #print(split_name)\n",
    "    \n",
    "    #now split the last bit at the \"_\" and the \".\" so you get \"EPOT\", \"250\", \"250\", \"mat\" and then you just take the coordinates\n",
    "    coords = re.split(\"_|\\.\", split_name[-1])\n",
    "    #print(coords)\n",
    "\n",
    "    x_coord = coords[0]\n",
    "    y_coord = coords[1]\n",
    "    #print(x_coord + ',' + y_coord)\n",
    "\n",
    "    file_location.loc[i, 'X'] = str(x_coord)\n",
    "    file_location.loc[i, 'Y'] = str(y_coord)\n",
    "    file_location.loc[i, 'Path'] = fpath\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fefb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "for idx, row in file_location.iterrows():\n",
    "    check = 0\n",
    "    x = float(row.X)\n",
    "\n",
    "    y = float(row.Y)\n",
    "\n",
    "    path = row.Path\n",
    "    if idx < 950:\n",
    "        P = readCSV(path)\n",
    "        finalP = flipArray(x, y, P)\n",
    "    \n",
    "        write_csv(x, y, finalP)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
